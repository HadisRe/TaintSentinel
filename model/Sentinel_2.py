"""
TaintSentinel - Part 2: GNN Models
Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø´Ø§Ù…Ù„ GlobalGNN Ùˆ PathGNN Ø¨Ø§ Hierarchical Aggregation Ø§Ø³Øª
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_mean_pool, global_max_pool
from torch_geometric.data import Data, Batch
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Import dataset from previous part
from Sentinel_1 import SmartContractDataset

# ===========================
# GlobalGNN Model
# ===========================

class GlobalGNN(nn.Module):
    """Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù„ Ú¯Ø±Ø§Ù"""

    def __init__(self, input_dim, hidden_dim, num_layers=3, dropout=0.2):
        super().__init__()
        self.convs = nn.ModuleList()
        self.bns = nn.ModuleList()

        # First layer
        self.convs.append(GCNConv(input_dim, hidden_dim))
        self.bns.append(nn.BatchNorm1d(hidden_dim))

        # Hidden layers
        for _ in range(num_layers - 1):
            self.convs.append(GCNConv(hidden_dim, hidden_dim))
            self.bns.append(nn.BatchNorm1d(hidden_dim))

        self.dropout = dropout
        self.hidden_dim = hidden_dim

    def forward(self, x, edge_index, batch):
        # Node-level processing
        for i, (conv, bn) in enumerate(zip(self.convs, self.bns)):
            x = conv(x, edge_index)
            x = bn(x)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)

        # Graph-level pooling - ØªØ±Ú©ÛŒØ¨ mean Ùˆ max pooling
        graph_embedding = torch.cat([
            global_mean_pool(x, batch),
            global_max_pool(x, batch)
        ], dim=1)

        return graph_embedding

# ===========================
# PathGNN Model with Hierarchical Aggregation
# ===========================

class PathGNN(nn.Module):
    """Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø³ÛŒØ±Ù‡Ø§ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª aggregation"""

    def __init__(self, node_embedding_dim, path_feature_dim, hidden_dim, dropout=0.2):
        super().__init__()

        # Ø¨Ø±Ø§ÛŒ embedding Ú¯Ø±Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³ÛŒØ±
        self.node_projection = nn.Linear(node_embedding_dim, hidden_dim)

        # LSTM Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ sequence
        self.lstm = nn.LSTM(
            input_size=hidden_dim,
            hidden_size=hidden_dim,
            num_layers=2,
            batch_first=True,
            bidirectional=True,
            dropout=dropout if dropout > 0 else 0
        )

        # Ø¨Ø±Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ Ø¨Ø§ path features
        self.feature_projection = nn.Linear(path_feature_dim, hidden_dim)
        self.path_fusion = nn.Linear(hidden_dim * 2 + hidden_dim, hidden_dim)

        # Hierarchical Aggregation layers
        self.attention_projection = nn.Linear(hidden_dim, 1)
        self.aggregation_mlp = nn.Sequential(
            nn.Linear(hidden_dim * 3, hidden_dim * 2),  # mean, max, weighted
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim * 2, hidden_dim)
        )

        self.dropout = dropout
        self.hidden_dim = hidden_dim

    def forward(self, path_data, node_embeddings):
        """
        Args:
            path_data: dict containing sequences, lengths, features, num_paths
            node_embeddings: node features from the graph
        Returns:
            aggregated_embedding: fixed-size representation of all paths
        """

        if path_data['num_paths'] == 0:
            # Ø§Ú¯Ø± Ù…Ø³ÛŒØ±ÛŒ Ù†Ø¯Ø§Ø±ÛŒÙ…ØŒ embedding ØµÙØ± Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…
            return torch.zeros(1, self.hidden_dim).to(node_embeddings.device)

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        sequences = path_data['sequences']  # [num_paths, max_seq_len]
        lengths = path_data['lengths']      # [num_paths]
        features = path_data['features']    # [num_paths, 6]
        num_paths = path_data['num_paths']

        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± Ù…Ø³ÛŒØ±
        path_embeddings = []

        for i in range(num_paths):
            seq_len = int(lengths[i])
            if seq_len > 0:
                # Ú¯Ø±ÙØªÙ† embedding Ú¯Ø±Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø³ÛŒØ±
                node_indices = sequences[i, :seq_len].long()  # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² integer Ø¨ÙˆØ¯Ù†
                path_nodes = node_embeddings[node_indices]
                path_nodes = self.node_projection(path_nodes)

                # LSTM processing
                lstm_out, (h_n, _) = self.lstm(path_nodes.unsqueeze(0))

                # Debug shapes
                # print(f"Debug - h_n shape: {h_n.shape}")

                # Ø¢Ø®Ø±ÛŒÙ† hidden state (bidirectional)
                # h_n shape: [num_layers*2, 1, hidden_dim]
                h_forward = h_n[-2].unsqueeze(0)   # [1, 1, hidden_dim]
                h_backward = h_n[-1].unsqueeze(0)  # [1, 1, hidden_dim]
                path_lstm = torch.cat([h_forward, h_backward], dim=2).squeeze(0)  # [1, hidden_dim*2]

                # ØªØ±Ú©ÛŒØ¨ Ø¨Ø§ path features
                path_feat = self.feature_projection(features[i].unsqueeze(0))  # [1, hidden_dim]

                # Fusion
                combined = torch.cat([path_lstm, path_feat], dim=1)  # [1, hidden_dim*2 + hidden_dim]
                path_embedding = self.path_fusion(combined)
                path_embedding = F.relu(path_embedding)
                path_embedding = path_embedding.squeeze(0)  # [hidden_dim]

                path_embeddings.append(path_embedding)

        # Stack all path embeddings
        if path_embeddings:  # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ù„ÛŒØ³Øª Ø®Ø§Ù„ÛŒ Ù†ÛŒØ³Øª
            path_embeddings = torch.stack(path_embeddings)  # [num_paths, hidden_dim]
        else:
            # Ø§Ú¯Ø± Ù‡ÛŒÚ† path Ù…Ø¹ØªØ¨Ø±ÛŒ Ù†Ø¯Ø§Ø´ØªÛŒÙ…
            return torch.zeros(1, self.hidden_dim).to(node_embeddings.device)

        # Hierarchical Aggregation
        # 1. Attention-weighted aggregation
        attention_scores = self.attention_projection(path_embeddings)  # [num_paths, 1]
        attention_weights = F.softmax(attention_scores, dim=0)
        weighted_paths = (path_embeddings * attention_weights).sum(dim=0, keepdim=True)  # [1, hidden_dim]

        # 2. Mean pooling
        mean_paths = path_embeddings.mean(dim=0, keepdim=True)  # [1, hidden_dim]

        # 3. Max pooling
        max_paths, _ = path_embeddings.max(dim=0, keepdim=True)  # [1, hidden_dim]

        # 4. Final aggregation
        aggregated = torch.cat([weighted_paths, mean_paths, max_paths], dim=1)  # [1, hidden_dim*3]
        aggregated_embedding = self.aggregation_mlp(aggregated)
        aggregated_embedding = F.dropout(aggregated_embedding, p=self.dropout, training=self.training)

        return aggregated_embedding

# ===========================
# Custom Collate Function
# ===========================

def custom_collate_fn(batch):
    """
    Custom collate function Ø¨Ø±Ø§ÛŒ batch processing Ø¨Ø§ ØªØ¹Ø¯Ø§Ø¯ Ù…ØªØºÛŒØ± Ù…Ø³ÛŒØ±
    """
    # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ graphs
    graphs = [item['graph'] for item in batch]
    batched_graph = Batch.from_data_list(graphs)

    # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ paths Ùˆ Ø³Ø§ÛŒØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    paths = [item['paths'] for item in batch]
    labels = torch.stack([item['label'] for item in batch])
    contract_ids = [item['contract_id'] for item in batch]
    has_paths = torch.tensor([item['has_paths'] for item in batch])

    return {
        'graph': batched_graph,
        'paths': paths,  # Ù„ÛŒØ³Øª Ø§Ø² dict Ù‡Ø§ - Ù‡Ø± Ú©Ø¯Ø§Ù… Ø¨Ø§ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø³ÛŒØ± Ù…ØªÙØ§ÙˆØª
        'labels': labels,
        'contract_ids': contract_ids,
        'has_paths': has_paths
    }

# ===========================
# Test Script
# ===========================

def test_models():
    """ØªØ³Øª GlobalGNN Ùˆ PathGNN"""
    print("ğŸ§ª Testing GNN Models...")
    print("="*60)

    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    base_path = r"C:\Users\Hadis\Documents\NewModel1"
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ Using device: {device}")

    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ dataset
    dataset = SmartContractDataset(
        base_path=base_path,
        batch_names=['batch1'],
        balanced=False
    )

    # Ú¯Ø±ÙØªÙ† ÛŒÚ© batch Ú©ÙˆÚ†Ú© Ø¨Ø±Ø§ÛŒ ØªØ³Øª
    from torch.utils.data import DataLoader
    test_loader = DataLoader(
        dataset,
        batch_size=4,
        shuffle=False,
        collate_fn=custom_collate_fn
    )

    # Ú¯Ø±ÙØªÙ† Ø§ÙˆÙ„ÛŒÙ† batch
    batch = next(iter(test_loader))

    print(f"\nğŸ“Š Batch info:")
    print(f"   - Batch size: {len(batch['labels'])}")
    print(f"   - Graph nodes: {batch['graph'].x.shape}")
    print(f"   - Number of paths per contract: {[p['num_paths'] for p in batch['paths']]}")

    # ØªØ³Øª GlobalGNN
    print("\n1ï¸âƒ£ Testing GlobalGNN:")
    node_feature_dim = batch['graph'].x.shape[1]
    global_gnn = GlobalGNN(
        input_dim=node_feature_dim,
        hidden_dim=128,
        num_layers=3
    ).to(device)

    # Forward pass
    batch['graph'] = batch['graph'].to(device)
    global_output = global_gnn(
        batch['graph'].x,
        batch['graph'].edge_index,
        batch['graph'].batch
    )
    print(f"   âœ… Global GNN output shape: {global_output.shape}")
    print(f"      Expected: [batch_size, hidden_dim*2] = [4, 256]")

    # ØªØ³Øª PathGNN
    print("\n2ï¸âƒ£ Testing PathGNN:")
    path_gnn = PathGNN(
        node_embedding_dim=node_feature_dim,
        path_feature_dim=6,
        hidden_dim=64
    ).to(device)

    # ØªØ³Øª Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø¯Ø± batch
    path_outputs = []
    for i in range(len(batch['labels'])):
        # Ú¯Ø±ÙØªÙ† node embeddings Ø§ÛŒÙ† Ú¯Ø±Ø§Ù
        graph_mask = (batch['graph'].batch == i)
        graph_nodes = batch['graph'].x[graph_mask]

        # Ù¾Ø±Ø¯Ø§Ø²Ø´ paths
        path_data = batch['paths'][i]
        # Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ device
        for key in ['sequences', 'lengths', 'features']:
            if key in path_data:
                path_data[key] = path_data[key].to(device)

        print(f"\n   Processing contract {i+1}:")
        print(f"      - Graph nodes shape: {graph_nodes.shape}")
        print(f"      - Number of paths: {path_data['num_paths']}")

        path_output = path_gnn(path_data, graph_nodes)
        path_outputs.append(path_output)

        print(f"      - Output shape: {path_output.shape}")

    # Stack outputs
    path_outputs = torch.cat(path_outputs, dim=0)
    print(f"\n   âœ… Final path embeddings shape: {path_outputs.shape}")
    print(f"      Expected: [batch_size, hidden_dim] = [4, 64]")

    # ØªØ³Øª Ø­Ø§Ù„Øª Ø®Ø§Øµ: Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø¨Ø¯ÙˆÙ† Ù…Ø³ÛŒØ±
    print("\n3ï¸âƒ£ Testing edge case (no paths):")
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† graph_nodes Ø§Ø² loop Ù‚Ø¨Ù„ÛŒ
    empty_path_data = {
        'sequences': torch.zeros(1, 20).long().to(device),
        'lengths': torch.zeros(1).long().to(device),
        'features': torch.zeros(1, 6).float().to(device),
        'num_paths': 0
    }
    empty_output = path_gnn(empty_path_data, graph_nodes)
    print(f"   âœ… Empty path output shape: {empty_output.shape}")
    print(f"      All zeros: {torch.all(empty_output == 0).item()}")
    
    print("\nâœ… Model tests completed successfully!")
    

if __name__ == "__main__":
    test_models()